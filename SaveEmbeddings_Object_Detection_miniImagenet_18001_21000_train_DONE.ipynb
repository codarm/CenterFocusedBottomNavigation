{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "SaveEmbeddings_Object_Detection_miniImagenet_18001_21000_train_DONE.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "RGlVnbugxFK2",
        "3rKe3HqM523g",
        "OLU-gp7n8__E",
        "5JCHA5Q8eiOo"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6aa62021259a450b8d9da73ec3f53dd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5125cd2b89034171aa81a4d315d5a2e3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0916918b22e049e7a4009b2432027219",
              "IPY_MODEL_a72783368b464fa8bb017f80dec5b759"
            ]
          }
        },
        "5125cd2b89034171aa81a4d315d5a2e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0916918b22e049e7a4009b2432027219": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6eaa03f7a1f74bf6af28062578fb9e19",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 102502400,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 102502400,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7747a57b0ce8436f91c3995e1c009ed7"
          }
        },
        "a72783368b464fa8bb017f80dec5b759": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4698eb1ed7f34fe5b5ff5a83108ea69e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 97.8M/97.8M [03:14&lt;00:00, 527kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8f3820b6037b4953a30566b1b940e2f1"
          }
        },
        "6eaa03f7a1f74bf6af28062578fb9e19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7747a57b0ce8436f91c3995e1c009ed7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4698eb1ed7f34fe5b5ff5a83108ea69e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8f3820b6037b4953a30566b1b940e2f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6f0a334c02e34c75905e9f1ae37f11b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8eda9d97ce9b405fbfd22bc32165f353",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d05f75b0baa240b7b9bcf0e53e139ac8",
              "IPY_MODEL_5ce7da1ab66b485a8ab3ab2e9544495a"
            ]
          }
        },
        "8eda9d97ce9b405fbfd22bc32165f353": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d05f75b0baa240b7b9bcf0e53e139ac8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_82f13a98f3714de08b8b389780b9691c",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 113703565,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 113703565,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_071e812315cd40348a857e4331753c5e"
          }
        },
        "5ce7da1ab66b485a8ab3ab2e9544495a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_eae80038de2440318934bc5dec312ec1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 108M/108M [00:05&lt;00:00, 19.5MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_81a9a86efd9d4755a8029247abc8839a"
          }
        },
        "82f13a98f3714de08b8b389780b9691c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "071e812315cd40348a857e4331753c5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "eae80038de2440318934bc5dec312ec1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "81a9a86efd9d4755a8029247abc8839a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/codarm/CenterFocusedBottomNavigation/blob/master/SaveEmbeddings_Object_Detection_miniImagenet_18001_21000_train_DONE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wCVCAfpyE0A"
      },
      "source": [
        "# Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXAPOzOK4mTl",
        "outputId": "1e50e58c-5513-4548-da4e-67632d60b515"
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "!pip install httplib2==0.15.0\n",
        "import os\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from pydrive.files import GoogleDriveFileList\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "from getpass import getpass\n",
        "import urllib\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# Cloning PAL_2021 for modules.\n",
        "# Need password to access private repo.\n",
        "\n",
        "if 'PAL_2021' not in os.listdir():\n",
        "    user = input('Github User name: ')\n",
        "    password = getpass('Password: ')\n",
        "    password = urllib.parse.quote(password) # your password is converted into url format\n",
        "\n",
        "    cmd_string = 'git clone https://{0}:{1}@github.com/minakhan01/PAL_2021.git'.format(user, password)\n",
        "\n",
        "    os.system(cmd_string)\n",
        "    cmd_string, password = \"\", \"\" # removing the password from the variable"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting httplib2==0.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/be/83/5e006e25403871ffbbf587c7aa4650158c947d46e89f2d50dcaf018464de/httplib2-0.15.0-py3-none-any.whl (94kB)\n",
            "\r\u001b[K     |███▌                            | 10kB 23.5MB/s eta 0:00:01\r\u001b[K     |███████                         | 20kB 30.6MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 30kB 21.5MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 40kB 25.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 51kB 24.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 61kB 26.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 71kB 18.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 81kB 19.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 92kB 18.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 102kB 9.2MB/s \n",
            "\u001b[?25hInstalling collected packages: httplib2\n",
            "  Found existing installation: httplib2 0.17.4\n",
            "    Uninstalling httplib2-0.17.4:\n",
            "      Successfully uninstalled httplib2-0.17.4\n",
            "Successfully installed httplib2-0.15.0\n",
            "Github User name: codarm\n",
            "Password: ··········\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGlVnbugxFK2"
      },
      "source": [
        "# Installation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rKe3HqM523g"
      },
      "source": [
        "## Install CLIP dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poS-WNDixIhY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2e3bec0-b1e3-4ae8-a453-fa900464f45f"
      },
      "source": [
        "import subprocess\n",
        "\n",
        "CUDA_version = [s for s in subprocess.check_output([\"nvcc\", \"--version\"]).decode(\"UTF-8\").split(\", \") if s.startswith(\"release\")][0].split(\" \")[-1]\n",
        "print(\"CUDA version:\", CUDA_version)\n",
        "\n",
        "if CUDA_version == \"10.0\":\n",
        "    torch_version_suffix = \"+cu100\"\n",
        "elif CUDA_version == \"10.1\":\n",
        "    torch_version_suffix = \"+cu101\"\n",
        "elif CUDA_version == \"10.2\":\n",
        "    torch_version_suffix = \"\"\n",
        "else:\n",
        "    torch_version_suffix = \"+cu110\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA version: 11.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uA-69W8M59nA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26dcecd1-5eaf-4895-c536-48bacc65af36"
      },
      "source": [
        "! pip install torch==1.7.1{torch_version_suffix} torchvision==0.8.2{torch_version_suffix} -f https://download.pytorch.org/whl/torch_stable.html ftfy regex"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.7.1+cu110\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu110/torch-1.7.1%2Bcu110-cp37-cp37m-linux_x86_64.whl (1156.8MB)\n",
            "\u001b[K     |███████████████████████         | 834.1MB 1.1MB/s eta 0:04:58tcmalloc: large alloc 1147494400 bytes == 0x56556319c000 @  0x7f51330f1615 0x56552a30f06c 0x56552a3eeeba 0x56552a311e8d 0x56552a40399d 0x56552a385fe9 0x56552a380b0e 0x56552a31377a 0x56552a385e50 0x56552a380b0e 0x56552a31377a 0x56552a38286a 0x56552a4047c6 0x56552a381ee2 0x56552a4047c6 0x56552a381ee2 0x56552a4047c6 0x56552a381ee2 0x56552a4047c6 0x56552a486431 0x56552a3e7049 0x56552a351c84 0x56552a3128e9 0x56552a386ade 0x56552a31369a 0x56552a381a45 0x56552a380e0d 0x56552a31377a 0x56552a381a45 0x56552a31369a 0x56552a381a45\n",
            "\u001b[K     |█████████████████████████████▏  | 1055.7MB 1.2MB/s eta 0:01:26tcmalloc: large alloc 1434370048 bytes == 0x5655a77f2000 @  0x7f51330f1615 0x56552a30f06c 0x56552a3eeeba 0x56552a311e8d 0x56552a40399d 0x56552a385fe9 0x56552a380b0e 0x56552a31377a 0x56552a385e50 0x56552a380b0e 0x56552a31377a 0x56552a38286a 0x56552a4047c6 0x56552a381ee2 0x56552a4047c6 0x56552a381ee2 0x56552a4047c6 0x56552a381ee2 0x56552a4047c6 0x56552a486431 0x56552a3e7049 0x56552a351c84 0x56552a3128e9 0x56552a386ade 0x56552a31369a 0x56552a381a45 0x56552a380e0d 0x56552a31377a 0x56552a381a45 0x56552a31369a 0x56552a381a45\n",
            "\u001b[K     |████████████████████████████████| 1156.7MB 1.1MB/s eta 0:00:01tcmalloc: large alloc 1445945344 bytes == 0x5655fcfde000 @  0x7f51330f1615 0x56552a30f06c 0x56552a3eeeba 0x56552a311e8d 0x56552a40399d 0x56552a385fe9 0x56552a380b0e 0x56552a31377a 0x56552a381c9e 0x56552a380b0e 0x56552a31377a 0x56552a381c9e 0x56552a380b0e 0x56552a31377a 0x56552a381c9e 0x56552a380b0e 0x56552a31377a 0x56552a381c9e 0x56552a380b0e 0x56552a31377a 0x56552a381c9e 0x56552a31369a 0x56552a381c9e 0x56552a380b0e 0x56552a31377a 0x56552a38286a 0x56552a380b0e 0x56552a31377a 0x56552a38286a 0x56552a380b0e 0x56552a313e11\n",
            "\u001b[K     |████████████████████████████████| 1156.8MB 16kB/s \n",
            "\u001b[?25hCollecting torchvision==0.8.2+cu110\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu110/torchvision-0.8.2%2Bcu110-cp37-cp37m-linux_x86_64.whl (12.9MB)\n",
            "\u001b[K     |████████████████████████████████| 12.9MB 241kB/s \n",
            "\u001b[?25hCollecting ftfy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/04/06/e5c80e2e0f979628d47345efba51f7ba386fe95963b11c594209085f5a9b/ftfy-5.9.tar.gz (66kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 7.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1+cu110) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1+cu110) (3.7.4.3)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.8.2+cu110) (7.0.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy) (0.2.5)\n",
            "Building wheels for collected packages: ftfy\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ftfy: filename=ftfy-5.9-cp37-none-any.whl size=46451 sha256=5a06a0c2dc9801387f69d2db30609c9c8cc9b3cc0ac1a3247e087550e6ee7e9f\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/2e/f0/b07196e8c929114998f0316894a61c752b63bfa3fdd50d2fc3\n",
            "Successfully built ftfy\n",
            "\u001b[31mERROR: torchtext 0.9.0 has requirement torch==1.8.0, but you'll have torch 1.7.1+cu110 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch, torchvision, ftfy\n",
            "  Found existing installation: torch 1.8.0+cu101\n",
            "    Uninstalling torch-1.8.0+cu101:\n",
            "      Successfully uninstalled torch-1.8.0+cu101\n",
            "  Found existing installation: torchvision 0.9.0+cu101\n",
            "    Uninstalling torchvision-0.9.0+cu101:\n",
            "      Successfully uninstalled torchvision-0.9.0+cu101\n",
            "Successfully installed ftfy-5.9 torch-1.7.1+cu110 torchvision-0.8.2+cu110\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYwBZS1N6A3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2db34cda-55ff-4639-8b37-491399a26077"
      },
      "source": [
        "! pip install ftfy regex\n",
        "! wget https://openaipublic.azureedge.net/clip/bpe_simple_vocab_16e6.txt.gz -O bpe_simple_vocab_16e6.txt.gz"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.7/dist-packages (5.9)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (2019.12.20)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy) (0.2.5)\n",
            "--2021-03-29 13:30:26--  https://openaipublic.azureedge.net/clip/bpe_simple_vocab_16e6.txt.gz\n",
            "Resolving openaipublic.azureedge.net (openaipublic.azureedge.net)... 13.107.246.19, 13.107.213.19, 2620:1ec:bdf::19, ...\n",
            "Connecting to openaipublic.azureedge.net (openaipublic.azureedge.net)|13.107.246.19|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1356917 (1.3M) [application/octet-stream]\n",
            "Saving to: ‘bpe_simple_vocab_16e6.txt.gz’\n",
            "\n",
            "bpe_simple_vocab_16 100%[===================>]   1.29M  --.-KB/s    in 0.03s   \n",
            "\n",
            "2021-03-29 13:30:27 (44.1 MB/s) - ‘bpe_simple_vocab_16e6.txt.gz’ saved [1356917/1356917]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oIcNBYB8lz3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab615633-df2b-4c75-aa4e-2239138e2c99"
      },
      "source": [
        "!pip install git+https://github.com/Sri-vatsa/CLIP # using this fork because of visualization capabilities"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/Sri-vatsa/CLIP\n",
            "  Cloning https://github.com/Sri-vatsa/CLIP to /tmp/pip-req-build-n4v_4iit\n",
            "  Running command git clone -q https://github.com/Sri-vatsa/CLIP /tmp/pip-req-build-n4v_4iit\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (5.9)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (2019.12.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (4.41.1)\n",
            "Requirement already satisfied: torch~=1.7.1 in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (1.7.1+cu110)\n",
            "Requirement already satisfied: torchvision~=0.8.2 in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (0.8.2+cu110)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy->clip==1.0) (0.2.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch~=1.7.1->clip==1.0) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch~=1.7.1->clip==1.0) (1.19.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision~=0.8.2->clip==1.0) (7.0.0)\n",
            "Building wheels for collected packages: clip\n",
            "  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clip: filename=clip-1.0-cp37-none-any.whl size=1368623 sha256=b542863391a2910ec1536a606d50bd99069c14d574e484b68863cf38e6bc23f7\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-nsr4gi5z/wheels/cc/55/69/0d411dabbd5009fd069d47b47cf7839c54e595dc61725b307b\n",
            "Successfully built clip\n",
            "Installing collected packages: clip\n",
            "Successfully installed clip-1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLU-gp7n8__E"
      },
      "source": [
        "## Install clustering dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TLg9ozo9Hvc"
      },
      "source": [
        "!pip -q install umap-learn>=0.3.7"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9z1WQnXdLHy2"
      },
      "source": [
        "## Install dataset manager dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1vvMx7_LLSp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5722b4a-77c1-4f8e-b4e1-f2e9c56d8630"
      },
      "source": [
        "!pip install wget"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp37-none-any.whl size=9681 sha256=580aab549e9d892907252b7d797ae4a942350ccb81d95b63b8b1456f9aca7b58\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzsubsEm72rr"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZI62a6G74kw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08f6828d-242c-4754-f2dc-fd05e5c522dc"
      },
      "source": [
        "# ML Libraries\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "import keras\n",
        "\n",
        "# Data processing\n",
        "import PIL\n",
        "import base64\n",
        "import imageio\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "from PIL import Image\n",
        "import cv2\n",
        "\n",
        "# Plotting\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from IPython.core.display import display, HTML\n",
        "from matplotlib import cm\n",
        "\n",
        "# Models\n",
        "import clip\n",
        "\n",
        "# Datasets\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "# Clustering\n",
        "import umap\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.cluster import KMeans\n",
        "from yellowbrick.cluster import KElbowVisualizer\n",
        "\n",
        "# Misc\n",
        "import progressbar\n",
        "import logging\n",
        "from abc import ABC, abstractmethod\n",
        "import time\n",
        "import urllib.request\n",
        "import os\n",
        "\n",
        "# Modules\n",
        "from PAL_2021.PAL_HILL.ExperimentModules import embedding_models\n",
        "from PAL_2021.PAL_HILL.ExperimentModules.dataset_manager import DatasetManager\n",
        "from PAL_2021.PAL_HILL.ExperimentModules.utils import (save_npy, load_npy, \n",
        "                                                       get_folder_id, \n",
        "                                                       create_expt_dir, \n",
        "                                                       save_to_drive, \n",
        "                                                       load_all_from_drive_folder, \n",
        "                                                       download_file_by_name, \n",
        "                                                       delete_file_by_name)\n",
        "\n",
        "logging.getLogger('googleapicliet.discovery_cache').setLevel(logging.ERROR)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zU_gxQ0KbwMh"
      },
      "source": [
        "# Initialization & Constants\n",
        "\n",
        "**Edited**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bih5tBPdbx3u"
      },
      "source": [
        "# IMG_HEIGHT = 224\n",
        "# IMG_WIDTH = 224\n",
        "\n",
        "# encoder_model_name = \"ViT-B/32\"\n",
        "experiment_id = \"MiniImagenet-\"\n",
        "\n",
        "folder_name = experiment_id+\"Object-Detection-19-03-21\"\n",
        "\n",
        "# Change parentid to match that of experiments root folder in gdrive\n",
        "parentid = '1bK72W-Um20EQDEyChNhNJthUNbmoSEjD'\n",
        "\n",
        "# Filepaths\n",
        "# results_filepath = experiment_id + \"-\" + \"results.json\"\n",
        "# embeddings_filepath = experiment_id + \"-\" + \"embeddings.npz\"\n",
        "# obj_det_output_filepath = experiment_id + \"-\" + \"obj-det-output.npz\""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBOFLDPL0RNK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14d4c9b6-46f1-4d0b-bacd-bdad45c35ece"
      },
      "source": [
        "# Initialize sepcific experiment folder in drive\n",
        "folderid = get_folder_id(drive, parentid, folder_name)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "title: MiniImagenet-Object-Detection-19-03-21, id: 136KFUQrN06W8qj2IKImshmpeYS2BerQI\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JCHA5Q8eiOo"
      },
      "source": [
        "# Embedding function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYmYbX2D8Mux"
      },
      "source": [
        "def run_data_through_model(\n",
        "    data, \n",
        "    embedder, \n",
        "    filename, \n",
        "    drive,\n",
        "    folderid,\n",
        "    total_num_images,\n",
        "    max_num_samples=5000\n",
        "):\n",
        "    embedder.load_model()\n",
        "\n",
        "    embeddings = None\n",
        "    num_images_done = 0\n",
        "\n",
        "    while embeddings is None or num_images_done < total_num_images:\n",
        "        download_file_by_name(drive, folderid, filename)\n",
        "\n",
        "        if filename in os.listdir():\n",
        "            embeddings = np.load(filename)['data']\n",
        "            num_images_done = embeddings.shape[0]\n",
        "            if num_images_done == total_num_images:\n",
        "                print(\"All images done already.\")\n",
        "                break\n",
        "            else:\n",
        "                print(\"{}/{} images done already\".format(\n",
        "                    num_images_done, total_num_images)\n",
        "                )\n",
        "\n",
        "        print(\"Running for image indices {}-{}.\".format(\n",
        "            num_images_done, num_images_done+max_num_samples\n",
        "            )\n",
        "        )\n",
        "        if (num_images_done+max_num_samples) <= total_num_images:\n",
        "            batch = data[num_images_done:num_images_done+max_num_samples]\n",
        "        else:\n",
        "            batch = data[num_images_done:]\n",
        "\n",
        "        processed_batch = embedder.preprocess_data(batch)\n",
        "        embeddings_batch = embedder.embed_images(\n",
        "            processed_batch, batch_size=50\n",
        "            )\n",
        "        \n",
        "        if embeddings is None:\n",
        "            embeddings = embeddings_batch\n",
        "        else:\n",
        "            embeddings = np.concatenate(\n",
        "                [embeddings, embeddings_batch]\n",
        "                )\n",
        "            \n",
        "        delete_file_by_name(drive, folderid, filename)\n",
        "        embedder.save_embeddings_to_drive(\n",
        "            embeddings, \n",
        "            filename,\n",
        "            drive,\n",
        "            folderid\n",
        "            )\n",
        "        num_images_done = embeddings.shape[0]\n",
        "        print(\"{}/{} images done\".format(num_images_done, total_num_images))\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6dBZ8gEJmrr"
      },
      "source": [
        "# Train data split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Sdn6HMixMH9"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcP9Ir-IxQoX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "654ee7c1-811d-4b23-da95-ae45f2104e12"
      },
      "source": [
        "download_file_by_name(drive,folderid[0],\"MiniImagenet_train_Detected_Images_18001_21000.npz\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading MiniImagenet_train_Detected_Images_18001_21000.npz from GDrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "6aa62021259a450b8d9da73ec3f53dd5",
            "5125cd2b89034171aa81a4d315d5a2e3",
            "0916918b22e049e7a4009b2432027219",
            "a72783368b464fa8bb017f80dec5b759",
            "6eaa03f7a1f74bf6af28062578fb9e19",
            "7747a57b0ce8436f91c3995e1c009ed7",
            "4698eb1ed7f34fe5b5ff5a83108ea69e",
            "8f3820b6037b4953a30566b1b940e2f1",
            "6f0a334c02e34c75905e9f1ae37f11b5",
            "8eda9d97ce9b405fbfd22bc32165f353",
            "d05f75b0baa240b7b9bcf0e53e139ac8",
            "5ce7da1ab66b485a8ab3ab2e9544495a",
            "82f13a98f3714de08b8b389780b9691c",
            "071e812315cd40348a857e4331753c5e",
            "eae80038de2440318934bc5dec312ec1",
            "81a9a86efd9d4755a8029247abc8839a"
          ]
        },
        "id": "pOt3rhr71riE",
        "outputId": "54957b68-8a33-4953-f2b4-2d004fcb60d4"
      },
      "source": [
        "data = np.load(\"MiniImagenet_train_Detected_Images_18001_21000.npz\")\n",
        "train_data = data[\"arr_0\"]\n",
        "data = []\n",
        "completed = 0\n",
        "total_train_images = train_data.shape[0]\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "max_num_samples = 500 # Colab crashes with too many images\n",
        "inceptionv3_train_filename = 'inceptionv3_embeddings_train_18001_21000.npz'\n",
        "\n",
        "inceptionv3_train_embedder = embedding_models.InceptionV3EmbeddingWrapper()\n",
        "\n",
        "run_data_through_model(\n",
        "    train_data, \n",
        "    inceptionv3_train_embedder, \n",
        "    inceptionv3_train_filename,\n",
        "    drive,\n",
        "    folderid[0],\n",
        "    total_train_images,\n",
        "    max_num_samples\n",
        "    )\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "\n",
        "max_num_samples = 1000\n",
        "resnet50_train_filename = 'resnet50_embeddings_train_18001_21000.npz'\n",
        "\n",
        "resnet50_train_embedder = embedding_models.Resnet50EmbeddingWrapper()\n",
        "\n",
        "run_data_through_model(\n",
        "    train_data, \n",
        "    resnet50_train_embedder, \n",
        "    resnet50_train_filename,\n",
        "    drive,\n",
        "    folderid[0],\n",
        "    total_train_images,\n",
        "    max_num_samples\n",
        "    )\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "max_num_samples = 2000\n",
        "moco_resnet50_train_filename = 'moco_resnet50_embeddings_train_18001_21000.npz'\n",
        "\n",
        "moco_resnet50_train_embedder = embedding_models.MoCoResnet50EmbeddingWrapper()\n",
        "\n",
        "run_data_through_model(\n",
        "    train_data, \n",
        "    moco_resnet50_train_embedder, \n",
        "    moco_resnet50_train_filename,\n",
        "    drive,\n",
        "    folderid[0],\n",
        "    total_train_images,\n",
        "    max_num_samples\n",
        "    )\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "max_num_samples = 2000\n",
        "pcl_resnet50_train_filename = 'pcl_resnet50_embeddings_train_18001_21000.npz'\n",
        "\n",
        "pcl_resnet50_train_embedder = embedding_models.PCLResnet50EmbeddingWrapper()\n",
        "\n",
        "run_data_through_model(\n",
        "    train_data, \n",
        "    pcl_resnet50_train_embedder, \n",
        "    pcl_resnet50_train_filename,\n",
        "    drive,\n",
        "    folderid[0],\n",
        "    total_train_images,\n",
        "    max_num_samples\n",
        "    )\n",
        "\n",
        "# auth.authenticate_user()\n",
        "# gauth = GoogleAuth()\n",
        "# gauth.credentials = GoogleCredentials.get_application_default()\n",
        "# drive = GoogleDrive(gauth)\n",
        "\n",
        "# max_num_samples = 100\n",
        "# clip_train_filename = 'clip_embeddings_train.npz'\n",
        "\n",
        "# clip_train_embedder = embedding_models.CLIPEmbeddingWrapper()\n",
        "\n",
        "# run_data_through_model(\n",
        "#     train_data, \n",
        "#     clip_train_embedder, \n",
        "#     clip_train_filename,\n",
        "#     drive,\n",
        "#     folderid[0],\n",
        "#     total_train_images,\n",
        "#     max_num_samples\n",
        "#     )\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "max_num_samples = 1000\n",
        "vgg16_train_filename = 'vgg16_embeddings_train_18001_21000.npz'\n",
        "\n",
        "vgg16_train_embedder = embedding_models.VGG16EmbeddingWrapper()\n",
        "\n",
        "run_data_through_model(\n",
        "    train_data, \n",
        "    vgg16_train_embedder, \n",
        "    vgg16_train_filename,\n",
        "    drive,\n",
        "    folderid[0],\n",
        "    total_train_images,\n",
        "    max_num_samples\n",
        "    )\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "max_num_samples = 2000\n",
        "simclr_train_filename = 'simclr_embeddings_train_18001_21000.npz'\n",
        "\n",
        "simclr_train_embedder = embedding_models.SimCLREmbeddingWrapper()\n",
        "\n",
        "run_data_through_model(\n",
        "    train_data, \n",
        "    simclr_train_embedder, \n",
        "    simclr_train_filename,\n",
        "    drive,\n",
        "    folderid[0],\n",
        "    total_train_images,\n",
        "    max_num_samples\n",
        "    )\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "max_num_samples = 1500\n",
        "swav_resnet50_train_filename = 'swav_resnet50_embeddings_train_18001_21000.npz'\n",
        "\n",
        "swav_resnet50_train_embedder = embedding_models.SwAVResnet50EmbeddingWrapper()\n",
        "\n",
        "run_data_through_model(\n",
        "    train_data, \n",
        "    swav_resnet50_train_embedder, \n",
        "    swav_resnet50_train_filename,\n",
        "    drive,\n",
        "    folderid[0],\n",
        "    total_train_images,\n",
        "    max_num_samples\n",
        "    )"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 0s 0us/step\n",
            "Running for image indices 0-500.\n",
            "Data saved to inceptionv3_embeddings_train_18001_21000.npz\n",
            "Uploaded inceptionv3_embeddings_train_18001_21000.npz to https://drive.google.com/drive/u/1/folders/136KFUQrN06W8qj2IKImshmpeYS2BerQI\n",
            "500/2816 images done\n",
            "Downloading inceptionv3_embeddings_train_18001_21000.npz from GDrive\n",
            "500/2816 images done already\n",
            "Running for image indices 500-1000.\n",
            "Deleting inceptionv3_embeddings_train_18001_21000.npz from GDrive\n",
            "Data saved to inceptionv3_embeddings_train_18001_21000.npz\n",
            "Uploaded inceptionv3_embeddings_train_18001_21000.npz to https://drive.google.com/drive/u/1/folders/136KFUQrN06W8qj2IKImshmpeYS2BerQI\n",
            "1000/2816 images done\n",
            "Downloading inceptionv3_embeddings_train_18001_21000.npz from GDrive\n",
            "1000/2816 images done already\n",
            "Running for image indices 1000-1500.\n",
            "Deleting inceptionv3_embeddings_train_18001_21000.npz from GDrive\n",
            "Data saved to inceptionv3_embeddings_train_18001_21000.npz\n",
            "Uploaded inceptionv3_embeddings_train_18001_21000.npz to https://drive.google.com/drive/u/1/folders/136KFUQrN06W8qj2IKImshmpeYS2BerQI\n",
            "1500/2816 images done\n",
            "Downloading inceptionv3_embeddings_train_18001_21000.npz from GDrive\n",
            "1500/2816 images done already\n",
            "Running for image indices 1500-2000.\n",
            "Deleting inceptionv3_embeddings_train_18001_21000.npz from GDrive\n",
            "Data saved to inceptionv3_embeddings_train_18001_21000.npz\n",
            "Uploaded inceptionv3_embeddings_train_18001_21000.npz to https://drive.google.com/drive/u/1/folders/136KFUQrN06W8qj2IKImshmpeYS2BerQI\n",
            "2000/2816 images done\n",
            "Downloading inceptionv3_embeddings_train_18001_21000.npz from GDrive\n",
            "2000/2816 images done already\n",
            "Running for image indices 2000-2500.\n",
            "Deleting inceptionv3_embeddings_train_18001_21000.npz from GDrive\n",
            "Data saved to inceptionv3_embeddings_train_18001_21000.npz\n",
            "Uploaded inceptionv3_embeddings_train_18001_21000.npz to https://drive.google.com/drive/u/1/folders/136KFUQrN06W8qj2IKImshmpeYS2BerQI\n",
            "2500/2816 images done\n",
            "Downloading inceptionv3_embeddings_train_18001_21000.npz from GDrive\n",
            "2500/2816 images done already\n",
            "Running for image indices 2500-3000.\n",
            "Deleting inceptionv3_embeddings_train_18001_21000.npz from GDrive\n",
            "Data saved to inceptionv3_embeddings_train_18001_21000.npz\n",
            "Uploaded inceptionv3_embeddings_train_18001_21000.npz to https://drive.google.com/drive/u/1/folders/136KFUQrN06W8qj2IKImshmpeYS2BerQI\n",
            "2816/2816 images done\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6aa62021259a450b8d9da73ec3f53dd5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=102502400.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Running for image indices 0-1000.\n",
            "Data saved to resnet50_embeddings_train_18001_21000.npz\n",
            "Uploaded resnet50_embeddings_train_18001_21000.npz to https://drive.google.com/drive/u/1/folders/136KFUQrN06W8qj2IKImshmpeYS2BerQI\n",
            "1000/2816 images done\n",
            "Downloading resnet50_embeddings_train_18001_21000.npz from GDrive\n",
            "1000/2816 images done already\n",
            "Running for image indices 1000-2000.\n",
            "Deleting resnet50_embeddings_train_18001_21000.npz from GDrive\n",
            "Data saved to resnet50_embeddings_train_18001_21000.npz\n",
            "Uploaded resnet50_embeddings_train_18001_21000.npz to https://drive.google.com/drive/u/1/folders/136KFUQrN06W8qj2IKImshmpeYS2BerQI\n",
            "2000/2816 images done\n",
            "Downloading resnet50_embeddings_train_18001_21000.npz from GDrive\n",
            "2000/2816 images done already\n",
            "Running for image indices 2000-3000.\n",
            "Deleting resnet50_embeddings_train_18001_21000.npz from GDrive\n",
            "Data saved to resnet50_embeddings_train_18001_21000.npz\n",
            "Uploaded resnet50_embeddings_train_18001_21000.npz to https://drive.google.com/drive/u/1/folders/136KFUQrN06W8qj2IKImshmpeYS2BerQI\n",
            "2816/2816 images done\n",
            "Running for image indices 0-2000.\n",
            "Data saved to moco_resnet50_embeddings_train_18001_21000.npz\n",
            "Uploaded moco_resnet50_embeddings_train_18001_21000.npz to https://drive.google.com/drive/u/1/folders/136KFUQrN06W8qj2IKImshmpeYS2BerQI\n",
            "2000/2816 images done\n",
            "Downloading moco_resnet50_embeddings_train_18001_21000.npz from GDrive\n",
            "2000/2816 images done already\n",
            "Running for image indices 2000-4000.\n",
            "Deleting moco_resnet50_embeddings_train_18001_21000.npz from GDrive\n",
            "Data saved to moco_resnet50_embeddings_train_18001_21000.npz\n",
            "Uploaded moco_resnet50_embeddings_train_18001_21000.npz to https://drive.google.com/drive/u/1/folders/136KFUQrN06W8qj2IKImshmpeYS2BerQI\n",
            "2816/2816 images done\n",
            "Running for image indices 0-2000.\n",
            "Data saved to pcl_resnet50_embeddings_train_18001_21000.npz\n",
            "Uploaded pcl_resnet50_embeddings_train_18001_21000.npz to https://drive.google.com/drive/u/1/folders/136KFUQrN06W8qj2IKImshmpeYS2BerQI\n",
            "2000/2816 images done\n",
            "Downloading pcl_resnet50_embeddings_train_18001_21000.npz from GDrive\n",
            "2000/2816 images done already\n",
            "Running for image indices 2000-4000.\n",
            "Deleting pcl_resnet50_embeddings_train_18001_21000.npz from GDrive\n",
            "Data saved to pcl_resnet50_embeddings_train_18001_21000.npz\n",
            "Uploaded pcl_resnet50_embeddings_train_18001_21000.npz to https://drive.google.com/drive/u/1/folders/136KFUQrN06W8qj2IKImshmpeYS2BerQI\n",
            "2816/2816 images done\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467904/553467096 [==============================] - 4s 0us/step\n",
            "Running for image indices 0-1000.\n",
            "Data saved to vgg16_embeddings_train_18001_21000.npz\n",
            "Uploaded vgg16_embeddings_train_18001_21000.npz to https://drive.google.com/drive/u/1/folders/136KFUQrN06W8qj2IKImshmpeYS2BerQI\n",
            "1000/2816 images done\n",
            "Downloading vgg16_embeddings_train_18001_21000.npz from GDrive\n",
            "1000/2816 images done already\n",
            "Running for image indices 1000-2000.\n",
            "Deleting vgg16_embeddings_train_18001_21000.npz from GDrive\n",
            "Data saved to vgg16_embeddings_train_18001_21000.npz\n",
            "Uploaded vgg16_embeddings_train_18001_21000.npz to https://drive.google.com/drive/u/1/folders/136KFUQrN06W8qj2IKImshmpeYS2BerQI\n",
            "2000/2816 images done\n",
            "Downloading vgg16_embeddings_train_18001_21000.npz from GDrive\n",
            "2000/2816 images done already\n",
            "Running for image indices 2000-3000.\n",
            "Deleting vgg16_embeddings_train_18001_21000.npz from GDrive\n",
            "Data saved to vgg16_embeddings_train_18001_21000.npz\n",
            "Uploaded vgg16_embeddings_train_18001_21000.npz to https://drive.google.com/drive/u/1/folders/136KFUQrN06W8qj2IKImshmpeYS2BerQI\n",
            "2816/2816 images done\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_19_layer_call_and_return_conditional_losses_16240) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_53_layer_call_and_return_conditional_losses_23562) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_47_layer_call_and_return_conditional_losses_22288) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_6_layer_call_and_return_conditional_losses_30442) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_9_layer_call_and_return_conditional_losses_30802) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_45_layer_call_and_return_conditional_losses_35122) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_46_layer_call_and_return_conditional_losses_22072) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_46_layer_call_and_return_conditional_losses_35242) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_30_layer_call_and_return_conditional_losses_33322) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_2_layer_call_and_return_conditional_losses_29962) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_17_layer_call_and_return_conditional_losses_15808) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_35_layer_call_and_return_conditional_losses_33922) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_20_layer_call_and_return_conditional_losses_32122) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_44_layer_call_and_return_conditional_losses_21640) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_42_layer_call_and_return_conditional_losses_34762) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_1_layer_call_and_return_conditional_losses_29842) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_34_layer_call_and_return_conditional_losses_33802) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_55_layer_call_and_return_conditional_losses_23944) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_39_layer_call_and_return_conditional_losses_20560) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_36_layer_call_and_return_conditional_losses_19912) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_21_layer_call_and_return_conditional_losses_32242) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_4_layer_call_and_return_conditional_losses_30202) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_49_layer_call_and_return_conditional_losses_35602) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_38_layer_call_and_return_conditional_losses_34282) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_34_layer_call_and_return_conditional_losses_19480) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_9_layer_call_and_return_conditional_losses_14080) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_52_layer_call_and_return_conditional_losses_35962) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_53_layer_call_and_return_conditional_losses_29512) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_55_layer_call_and_return_conditional_losses_29728) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_49_layer_call_and_return_conditional_losses_22720) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_22_layer_call_and_return_conditional_losses_16888) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_29_layer_call_and_return_conditional_losses_33202) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_43_layer_call_and_return_conditional_losses_34882) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_3_layer_call_and_return_conditional_losses_12784) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_23_layer_call_and_return_conditional_losses_32482) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_44_layer_call_and_return_conditional_losses_35002) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_25_layer_call_and_return_conditional_losses_17536) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_14_layer_call_and_return_conditional_losses_15160) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_42_layer_call_and_return_conditional_losses_21208) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_28_layer_call_and_return_conditional_losses_33082) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_51_layer_call_and_return_conditional_losses_23152) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_layer_call_and_return_conditional_losses_12124) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_40_layer_call_and_return_conditional_losses_20776) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_35_layer_call_and_return_conditional_losses_19696) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_41_layer_call_and_return_conditional_losses_34642) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_18_layer_call_and_return_conditional_losses_16024) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_23_layer_call_and_return_conditional_losses_17104) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_8_layer_call_and_return_conditional_losses_30682) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_3_layer_call_and_return_conditional_losses_30082) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_12_layer_call_and_return_conditional_losses_31162) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_27_layer_call_and_return_conditional_losses_32962) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_6_layer_call_and_return_conditional_losses_13432) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_11_layer_call_and_return_conditional_losses_14512) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_layer_call_and_return_conditional_losses_29403) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_45_layer_call_and_return_conditional_losses_21856) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_39_layer_call_and_return_conditional_losses_34402) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_19_layer_call_and_return_conditional_losses_32002) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_29_layer_call_and_return_conditional_losses_18400) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_4_layer_call_and_return_conditional_losses_13000) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_1_layer_call_and_return_conditional_losses_12352) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_54_layer_call_and_return_conditional_losses_23756) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_41_layer_call_and_return_conditional_losses_20992) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_20_layer_call_and_return_conditional_losses_16456) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_40_layer_call_and_return_conditional_losses_34522) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_32_layer_call_and_return_conditional_losses_33562) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_13_layer_call_and_return_conditional_losses_14944) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_33_layer_call_and_return_conditional_losses_33682) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_30_layer_call_and_return_conditional_losses_18616) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_17_layer_call_and_return_conditional_losses_31762) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_7_layer_call_and_return_conditional_losses_30562) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_48_layer_call_and_return_conditional_losses_35482) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_12_layer_call_and_return_conditional_losses_14728) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_5_layer_call_and_return_conditional_losses_30322) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_13_layer_call_and_return_conditional_losses_31282) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_15_layer_call_and_return_conditional_losses_15376) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_18_layer_call_and_return_conditional_losses_31882) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_21_layer_call_and_return_conditional_losses_16672) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_54_layer_call_and_return_conditional_losses_29621) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_48_layer_call_and_return_conditional_losses_22504) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_31_layer_call_and_return_conditional_losses_18832) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_31_layer_call_and_return_conditional_losses_33442) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_16_layer_call_and_return_conditional_losses_31642) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_10_layer_call_and_return_conditional_losses_14296) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_24_layer_call_and_return_conditional_losses_32602) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_5_layer_call_and_return_conditional_losses_13216) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_16_layer_call_and_return_conditional_losses_15592) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_26_layer_call_and_return_conditional_losses_32842) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_28_layer_call_and_return_conditional_losses_18184) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_22_layer_call_and_return_conditional_losses_32362) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_47_layer_call_and_return_conditional_losses_35362) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_38_layer_call_and_return_conditional_losses_20344) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_25_layer_call_and_return_conditional_losses_32722) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_51_layer_call_and_return_conditional_losses_35842) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_50_layer_call_and_return_conditional_losses_35722) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_2_layer_call_and_return_conditional_losses_12568) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_8_layer_call_and_return_conditional_losses_13864) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_52_layer_call_and_return_conditional_losses_23368) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_27_layer_call_and_return_conditional_losses_17968) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_33_layer_call_and_return_conditional_losses_19264) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_26_layer_call_and_return_conditional_losses_17752) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_7_layer_call_and_return_conditional_losses_13648) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_11_layer_call_and_return_conditional_losses_31042) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_15_layer_call_and_return_conditional_losses_31522) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_10_layer_call_and_return_conditional_losses_30922) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_37_layer_call_and_return_conditional_losses_20128) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_37_layer_call_and_return_conditional_losses_34162) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_43_layer_call_and_return_conditional_losses_21424) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_14_layer_call_and_return_conditional_losses_31402) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_24_layer_call_and_return_conditional_losses_17320) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_36_layer_call_and_return_conditional_losses_34042) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_32_layer_call_and_return_conditional_losses_19048) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_50_layer_call_and_return_conditional_losses_22936) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:googleapiclient.discovery_cache:file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 33, in <module>\n",
            "    from oauth2client.contrib.locked_file import LockedFile\n",
            "ModuleNotFoundError: No module named 'oauth2client.contrib.locked_file'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 37, in <module>\n",
            "    from oauth2client.locked_file import LockedFile\n",
            "ModuleNotFoundError: No module named 'oauth2client.locked_file'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/__init__.py\", line 44, in autodetect\n",
            "    from . import file_cache\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 41, in <module>\n",
            "    \"file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\"\n",
            "ImportError: file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Running for image indices 0-2000.\n",
            "Data saved to simclr_embeddings_train_18001_21000.npz\n",
            "Uploaded simclr_embeddings_train_18001_21000.npz to https://drive.google.com/drive/u/1/folders/136KFUQrN06W8qj2IKImshmpeYS2BerQI\n",
            "2000/2816 images done\n",
            "Downloading simclr_embeddings_train_18001_21000.npz from GDrive\n",
            "2000/2816 images done already\n",
            "Running for image indices 2000-4000.\n",
            "Deleting simclr_embeddings_train_18001_21000.npz from GDrive\n",
            "Data saved to simclr_embeddings_train_18001_21000.npz\n",
            "Uploaded simclr_embeddings_train_18001_21000.npz to https://drive.google.com/drive/u/1/folders/136KFUQrN06W8qj2IKImshmpeYS2BerQI\n",
            "2816/2816 images done\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/facebookresearch/swav/archive/master.zip\" to /root/.cache/torch/hub/master.zip\n",
            "Downloading: \"https://dl.fbaipublicfiles.com/deepcluster/swav_800ep_pretrain.pth.tar\" to /root/.cache/torch/hub/checkpoints/swav_800ep_pretrain.pth.tar\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6f0a334c02e34c75905e9f1ae37f11b5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=113703565.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:googleapiclient.discovery_cache:file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 33, in <module>\n",
            "    from oauth2client.contrib.locked_file import LockedFile\n",
            "ModuleNotFoundError: No module named 'oauth2client.contrib.locked_file'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 37, in <module>\n",
            "    from oauth2client.locked_file import LockedFile\n",
            "ModuleNotFoundError: No module named 'oauth2client.locked_file'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/__init__.py\", line 44, in autodetect\n",
            "    from . import file_cache\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 41, in <module>\n",
            "    \"file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\"\n",
            "ImportError: file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Running for image indices 0-1500.\n",
            "Data saved to swav_resnet50_embeddings_train_18001_21000.npz\n",
            "Uploaded swav_resnet50_embeddings_train_18001_21000.npz to https://drive.google.com/drive/u/1/folders/136KFUQrN06W8qj2IKImshmpeYS2BerQI\n",
            "1500/2816 images done\n",
            "Downloading swav_resnet50_embeddings_train_18001_21000.npz from GDrive\n",
            "1500/2816 images done already\n",
            "Running for image indices 1500-3000.\n",
            "Deleting swav_resnet50_embeddings_train_18001_21000.npz from GDrive\n",
            "Data saved to swav_resnet50_embeddings_train_18001_21000.npz\n",
            "Uploaded swav_resnet50_embeddings_train_18001_21000.npz to https://drive.google.com/drive/u/1/folders/136KFUQrN06W8qj2IKImshmpeYS2BerQI\n",
            "2816/2816 images done\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}