{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "SaveEmbeddings_Object_Detection_miniImagenet_6001_9000_train_DONE.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "RGlVnbugxFK2",
        "3rKe3HqM523g",
        "OLU-gp7n8__E",
        "5JCHA5Q8eiOo"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e1e211bf9f1a4b769113d28a00437abe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f2f6c57cbfc04615bab4e7e3ddf90397",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_31b020215ab946a08d81c92418fc5d0f",
              "IPY_MODEL_359097e015264262b7ce9015814c495f"
            ]
          }
        },
        "f2f6c57cbfc04615bab4e7e3ddf90397": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "31b020215ab946a08d81c92418fc5d0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b3bb8dcd36f34821a931d0296cc0549a",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 102502400,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 102502400,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a721ef95ff994d9296b4256b102b3c8f"
          }
        },
        "359097e015264262b7ce9015814c495f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_36abe4f5ac574c64a15d1cd00642fcf2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 97.8M/97.8M [00:00&lt;00:00, 265MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_546bb1f2b4e344a09c770f2a97fbb87d"
          }
        },
        "b3bb8dcd36f34821a931d0296cc0549a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a721ef95ff994d9296b4256b102b3c8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "36abe4f5ac574c64a15d1cd00642fcf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "546bb1f2b4e344a09c770f2a97fbb87d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "13a58a37d8864148932714c1c7223f41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e8383e06fe6a4f95a0973e51fc02ea39",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_251ed22e40ed4e6390ad2801344c3aeb",
              "IPY_MODEL_f505757caecb4bbc8f03cb37d3ce2716"
            ]
          }
        },
        "e8383e06fe6a4f95a0973e51fc02ea39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "251ed22e40ed4e6390ad2801344c3aeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_221fa61197b7462fae1737714ab67732",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 113703565,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 113703565,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d584c3a4407f41b7932943590a3b26f5"
          }
        },
        "f505757caecb4bbc8f03cb37d3ce2716": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cafc9d6c45b24bc7a0308dfa1920bd8e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 108M/108M [00:05&lt;00:00, 22.4MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a33f442558d74573b9ee23ae4108671d"
          }
        },
        "221fa61197b7462fae1737714ab67732": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d584c3a4407f41b7932943590a3b26f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cafc9d6c45b24bc7a0308dfa1920bd8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a33f442558d74573b9ee23ae4108671d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/codarm/CenterFocusedBottomNavigation/blob/master/SaveEmbeddings_Object_Detection_miniImagenet_6001_9000_train_DONE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wCVCAfpyE0A"
      },
      "source": [
        "# Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXAPOzOK4mTl",
        "outputId": "1ab7dc68-01d8-410d-d9d2-6fa55dde198f"
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "!pip install httplib2==0.15.0\n",
        "import os\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from pydrive.files import GoogleDriveFileList\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "from getpass import getpass\n",
        "import urllib\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# Cloning PAL_2021 for modules.\n",
        "# Need password to access private repo.\n",
        "\n",
        "if 'PAL_2021' not in os.listdir():\n",
        "    user = input('Github User name: ')\n",
        "    password = getpass('Password: ')\n",
        "    password = urllib.parse.quote(password) # your password is converted into url format\n",
        "\n",
        "    cmd_string = 'git clone https://{0}:{1}@github.com/minakhan01/PAL_2021.git'.format(user, password)\n",
        "\n",
        "    os.system(cmd_string)\n",
        "    cmd_string, password = \"\", \"\" # removing the password from the variable"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting httplib2==0.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/be/83/5e006e25403871ffbbf587c7aa4650158c947d46e89f2d50dcaf018464de/httplib2-0.15.0-py3-none-any.whl (94kB)\n",
            "\r\u001b[K     |███▌                            | 10kB 25.8MB/s eta 0:00:01\r\u001b[K     |███████                         | 20kB 22.1MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 30kB 16.8MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 40kB 16.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 51kB 19.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 61kB 21.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 71kB 15.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 81kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 92kB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 102kB 9.1MB/s \n",
            "\u001b[?25hInstalling collected packages: httplib2\n",
            "  Found existing installation: httplib2 0.17.4\n",
            "    Uninstalling httplib2-0.17.4:\n",
            "      Successfully uninstalled httplib2-0.17.4\n",
            "Successfully installed httplib2-0.15.0\n",
            "Github User name: codarm\n",
            "Password: ··········\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGlVnbugxFK2"
      },
      "source": [
        "# Installation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rKe3HqM523g"
      },
      "source": [
        "## Install CLIP dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poS-WNDixIhY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38b4fd9c-2eb5-4905-acb6-7398a648491e"
      },
      "source": [
        "import subprocess\n",
        "\n",
        "CUDA_version = [s for s in subprocess.check_output([\"nvcc\", \"--version\"]).decode(\"UTF-8\").split(\", \") if s.startswith(\"release\")][0].split(\" \")[-1]\n",
        "print(\"CUDA version:\", CUDA_version)\n",
        "\n",
        "if CUDA_version == \"10.0\":\n",
        "    torch_version_suffix = \"+cu100\"\n",
        "elif CUDA_version == \"10.1\":\n",
        "    torch_version_suffix = \"+cu101\"\n",
        "elif CUDA_version == \"10.2\":\n",
        "    torch_version_suffix = \"\"\n",
        "else:\n",
        "    torch_version_suffix = \"+cu110\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA version: 11.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uA-69W8M59nA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf11af46-6dc6-4d3e-fada-739885565577"
      },
      "source": [
        "! pip install torch==1.7.1{torch_version_suffix} torchvision==0.8.2{torch_version_suffix} -f https://download.pytorch.org/whl/torch_stable.html ftfy regex"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.7.1+cu110\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu110/torch-1.7.1%2Bcu110-cp37-cp37m-linux_x86_64.whl (1156.8MB)\n",
            "\u001b[K     |███████████████████████         | 834.1MB 1.2MB/s eta 0:04:29tcmalloc: large alloc 1147494400 bytes == 0x55c4e06a2000 @  0x7f61bc1da615 0x55c4a733306c 0x55c4a7412eba 0x55c4a7335e8d 0x55c4a742799d 0x55c4a73a9fe9 0x55c4a73a4b0e 0x55c4a733777a 0x55c4a73a9e50 0x55c4a73a4b0e 0x55c4a733777a 0x55c4a73a686a 0x55c4a74287c6 0x55c4a73a5ee2 0x55c4a74287c6 0x55c4a73a5ee2 0x55c4a74287c6 0x55c4a73a5ee2 0x55c4a74287c6 0x55c4a74aa431 0x55c4a740b049 0x55c4a7375c84 0x55c4a73368e9 0x55c4a73aaade 0x55c4a733769a 0x55c4a73a5a45 0x55c4a73a4e0d 0x55c4a733777a 0x55c4a73a5a45 0x55c4a733769a 0x55c4a73a5a45\n",
            "\u001b[K     |█████████████████████████████▏  | 1055.7MB 1.2MB/s eta 0:01:24tcmalloc: large alloc 1434370048 bytes == 0x55c524cf8000 @  0x7f61bc1da615 0x55c4a733306c 0x55c4a7412eba 0x55c4a7335e8d 0x55c4a742799d 0x55c4a73a9fe9 0x55c4a73a4b0e 0x55c4a733777a 0x55c4a73a9e50 0x55c4a73a4b0e 0x55c4a733777a 0x55c4a73a686a 0x55c4a74287c6 0x55c4a73a5ee2 0x55c4a74287c6 0x55c4a73a5ee2 0x55c4a74287c6 0x55c4a73a5ee2 0x55c4a74287c6 0x55c4a74aa431 0x55c4a740b049 0x55c4a7375c84 0x55c4a73368e9 0x55c4a73aaade 0x55c4a733769a 0x55c4a73a5a45 0x55c4a73a4e0d 0x55c4a733777a 0x55c4a73a5a45 0x55c4a733769a 0x55c4a73a5a45\n",
            "\u001b[K     |████████████████████████████████| 1156.7MB 1.2MB/s eta 0:00:01tcmalloc: large alloc 1445945344 bytes == 0x55c57a4e4000 @  0x7f61bc1da615 0x55c4a733306c 0x55c4a7412eba 0x55c4a7335e8d 0x55c4a742799d 0x55c4a73a9fe9 0x55c4a73a4b0e 0x55c4a733777a 0x55c4a73a5c9e 0x55c4a73a4b0e 0x55c4a733777a 0x55c4a73a5c9e 0x55c4a73a4b0e 0x55c4a733777a 0x55c4a73a5c9e 0x55c4a73a4b0e 0x55c4a733777a 0x55c4a73a5c9e 0x55c4a73a4b0e 0x55c4a733777a 0x55c4a73a5c9e 0x55c4a733769a 0x55c4a73a5c9e 0x55c4a73a4b0e 0x55c4a733777a 0x55c4a73a686a 0x55c4a73a4b0e 0x55c4a733777a 0x55c4a73a686a 0x55c4a73a4b0e 0x55c4a7337e11\n",
            "\u001b[K     |████████████████████████████████| 1156.8MB 15kB/s \n",
            "\u001b[?25hCollecting torchvision==0.8.2+cu110\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu110/torchvision-0.8.2%2Bcu110-cp37-cp37m-linux_x86_64.whl (12.9MB)\n",
            "\u001b[K     |████████████████████████████████| 12.9MB 244kB/s \n",
            "\u001b[?25hCollecting ftfy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/04/06/e5c80e2e0f979628d47345efba51f7ba386fe95963b11c594209085f5a9b/ftfy-5.9.tar.gz (66kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 7.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1+cu110) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1+cu110) (3.7.4.3)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.8.2+cu110) (7.0.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy) (0.2.5)\n",
            "Building wheels for collected packages: ftfy\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ftfy: filename=ftfy-5.9-cp37-none-any.whl size=46451 sha256=89521250c2ef57a38a6fd9f254b743756eddc296d76e79ea314b6d64553a3e6f\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/2e/f0/b07196e8c929114998f0316894a61c752b63bfa3fdd50d2fc3\n",
            "Successfully built ftfy\n",
            "\u001b[31mERROR: torchtext 0.9.0 has requirement torch==1.8.0, but you'll have torch 1.7.1+cu110 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch, torchvision, ftfy\n",
            "  Found existing installation: torch 1.8.0+cu101\n",
            "    Uninstalling torch-1.8.0+cu101:\n",
            "      Successfully uninstalled torch-1.8.0+cu101\n",
            "  Found existing installation: torchvision 0.9.0+cu101\n",
            "    Uninstalling torchvision-0.9.0+cu101:\n",
            "      Successfully uninstalled torchvision-0.9.0+cu101\n",
            "Successfully installed ftfy-5.9 torch-1.7.1+cu110 torchvision-0.8.2+cu110\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYwBZS1N6A3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d481824-edf8-4067-ea44-3601b76898fa"
      },
      "source": [
        "! pip install ftfy regex\n",
        "! wget https://openaipublic.azureedge.net/clip/bpe_simple_vocab_16e6.txt.gz -O bpe_simple_vocab_16e6.txt.gz"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.7/dist-packages (5.9)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (2019.12.20)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy) (0.2.5)\n",
            "--2021-03-28 11:02:56--  https://openaipublic.azureedge.net/clip/bpe_simple_vocab_16e6.txt.gz\n",
            "Resolving openaipublic.azureedge.net (openaipublic.azureedge.net)... 13.107.246.19, 13.107.213.19, 2620:1ec:bdf::19, ...\n",
            "Connecting to openaipublic.azureedge.net (openaipublic.azureedge.net)|13.107.246.19|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1356917 (1.3M) [application/octet-stream]\n",
            "Saving to: ‘bpe_simple_vocab_16e6.txt.gz’\n",
            "\n",
            "bpe_simple_vocab_16 100%[===================>]   1.29M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2021-03-28 11:02:56 (54.7 MB/s) - ‘bpe_simple_vocab_16e6.txt.gz’ saved [1356917/1356917]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oIcNBYB8lz3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58025432-c388-41e3-c8c6-9a08b0d51a77"
      },
      "source": [
        "!pip install git+https://github.com/Sri-vatsa/CLIP # using this fork because of visualization capabilities"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/Sri-vatsa/CLIP\n",
            "  Cloning https://github.com/Sri-vatsa/CLIP to /tmp/pip-req-build-dag_1vyf\n",
            "  Running command git clone -q https://github.com/Sri-vatsa/CLIP /tmp/pip-req-build-dag_1vyf\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (5.9)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (2019.12.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (4.41.1)\n",
            "Requirement already satisfied: torch~=1.7.1 in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (1.7.1+cu110)\n",
            "Requirement already satisfied: torchvision~=0.8.2 in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (0.8.2+cu110)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy->clip==1.0) (0.2.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch~=1.7.1->clip==1.0) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch~=1.7.1->clip==1.0) (3.7.4.3)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision~=0.8.2->clip==1.0) (7.0.0)\n",
            "Building wheels for collected packages: clip\n",
            "  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clip: filename=clip-1.0-cp37-none-any.whl size=1368623 sha256=d502c307ef57d9995431aac486b8df2ee8e2c4a3345bfed68c8d1441945797a6\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-uhb8hrvg/wheels/cc/55/69/0d411dabbd5009fd069d47b47cf7839c54e595dc61725b307b\n",
            "Successfully built clip\n",
            "Installing collected packages: clip\n",
            "Successfully installed clip-1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLU-gp7n8__E"
      },
      "source": [
        "## Install clustering dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TLg9ozo9Hvc"
      },
      "source": [
        "!pip -q install umap-learn>=0.3.7"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9z1WQnXdLHy2"
      },
      "source": [
        "## Install dataset manager dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1vvMx7_LLSp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49e42111-7395-467b-f4e0-a43f4a6b291a"
      },
      "source": [
        "!pip install wget"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp37-none-any.whl size=9681 sha256=79f95942eb7adcdafe475b83835f942c309b0f306a4e2ec738c395a98281d5e8\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzsubsEm72rr"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZI62a6G74kw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5592a992-e780-4fbd-a447-220a5b14df66"
      },
      "source": [
        "# ML Libraries\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "import keras\n",
        "\n",
        "# Data processing\n",
        "import PIL\n",
        "import base64\n",
        "import imageio\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "from PIL import Image\n",
        "import cv2\n",
        "\n",
        "# Plotting\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from IPython.core.display import display, HTML\n",
        "from matplotlib import cm\n",
        "\n",
        "# Models\n",
        "import clip\n",
        "\n",
        "# Datasets\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "# Clustering\n",
        "import umap\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.cluster import KMeans\n",
        "from yellowbrick.cluster import KElbowVisualizer\n",
        "\n",
        "# Misc\n",
        "import progressbar\n",
        "import logging\n",
        "from abc import ABC, abstractmethod\n",
        "import time\n",
        "import urllib.request\n",
        "import os\n",
        "\n",
        "# Modules\n",
        "from PAL_2021.PAL_HILL.ExperimentModules import embedding_models\n",
        "from PAL_2021.PAL_HILL.ExperimentModules.dataset_manager import DatasetManager\n",
        "from PAL_2021.PAL_HILL.ExperimentModules.utils import (save_npy, load_npy, \n",
        "                                                       get_folder_id, \n",
        "                                                       create_expt_dir, \n",
        "                                                       save_to_drive, \n",
        "                                                       load_all_from_drive_folder, \n",
        "                                                       download_file_by_name, \n",
        "                                                       delete_file_by_name)\n",
        "\n",
        "logging.getLogger('googleapicliet.discovery_cache').setLevel(logging.ERROR)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zU_gxQ0KbwMh"
      },
      "source": [
        "# Initialization & Constants\n",
        "\n",
        "**Edited**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bih5tBPdbx3u"
      },
      "source": [
        "# IMG_HEIGHT = 224\n",
        "# IMG_WIDTH = 224\n",
        "\n",
        "# encoder_model_name = \"ViT-B/32\"\n",
        "experiment_id = \"MiniImagenet-\"\n",
        "\n",
        "folder_name = experiment_id+\"Object-Detection-19-03-21\"\n",
        "\n",
        "# Change parentid to match that of experiments root folder in gdrive\n",
        "parentid = '1bK72W-Um20EQDEyChNhNJthUNbmoSEjD'\n",
        "\n",
        "# Filepaths\n",
        "# results_filepath = experiment_id + \"-\" + \"results.json\"\n",
        "# embeddings_filepath = experiment_id + \"-\" + \"embeddings.npz\"\n",
        "# obj_det_output_filepath = experiment_id + \"-\" + \"obj-det-output.npz\""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBOFLDPL0RNK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7130e56-3cd3-4e09-fec9-e46a520e7bd9"
      },
      "source": [
        "# Initialize sepcific experiment folder in drive\n",
        "folderid = get_folder_id(drive, parentid, folder_name)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "title: MiniImagenet-Object-Detection-19-03-21, id: 136KFUQrN06W8qj2IKImshmpeYS2BerQI\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JCHA5Q8eiOo"
      },
      "source": [
        "# Embedding function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYmYbX2D8Mux"
      },
      "source": [
        "def run_data_through_model(\n",
        "    data, \n",
        "    embedder, \n",
        "    filename, \n",
        "    drive,\n",
        "    folderid,\n",
        "    total_num_images,\n",
        "    max_num_samples=5000\n",
        "):\n",
        "    embedder.load_model()\n",
        "\n",
        "    embeddings = None\n",
        "    num_images_done = 0\n",
        "\n",
        "    while embeddings is None or num_images_done < total_num_images:\n",
        "        download_file_by_name(drive, folderid, filename)\n",
        "\n",
        "        if filename in os.listdir():\n",
        "            embeddings = np.load(filename)['data']\n",
        "            num_images_done = embeddings.shape[0]\n",
        "            if num_images_done == total_num_images:\n",
        "                print(\"All images done already.\")\n",
        "                break\n",
        "            else:\n",
        "                print(\"{}/{} images done already\".format(\n",
        "                    num_images_done, total_num_images)\n",
        "                )\n",
        "\n",
        "        print(\"Running for image indices {}-{}.\".format(\n",
        "            num_images_done, num_images_done+max_num_samples\n",
        "            )\n",
        "        )\n",
        "        if (num_images_done+max_num_samples) <= total_num_images:\n",
        "            batch = data[num_images_done:num_images_done+max_num_samples]\n",
        "        else:\n",
        "            batch = data[num_images_done:]\n",
        "\n",
        "        processed_batch = embedder.preprocess_data(batch)\n",
        "        embeddings_batch = embedder.embed_images(\n",
        "            processed_batch, batch_size=50\n",
        "            )\n",
        "        \n",
        "        if embeddings is None:\n",
        "            embeddings = embeddings_batch\n",
        "        else:\n",
        "            embeddings = np.concatenate(\n",
        "                [embeddings, embeddings_batch]\n",
        "                )\n",
        "            \n",
        "        delete_file_by_name(drive, folderid, filename)\n",
        "        embedder.save_embeddings_to_drive(\n",
        "            embeddings, \n",
        "            filename,\n",
        "            drive,\n",
        "            folderid\n",
        "            )\n",
        "        num_images_done = embeddings.shape[0]\n",
        "        print(\"{}/{} images done\".format(num_images_done, total_num_images))\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6dBZ8gEJmrr"
      },
      "source": [
        "# Train data split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Sdn6HMixMH9"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcP9Ir-IxQoX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd913a3d-9d0f-4010-e19a-d329c434a2a7"
      },
      "source": [
        "download_file_by_name(drive,folderid[0],\"MiniImagenet_train_Detected_Images_6001_9000.npz\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading MiniImagenet_train_Detected_Images_6001_9000.npz from GDrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "e1e211bf9f1a4b769113d28a00437abe",
            "f2f6c57cbfc04615bab4e7e3ddf90397",
            "31b020215ab946a08d81c92418fc5d0f",
            "359097e015264262b7ce9015814c495f",
            "b3bb8dcd36f34821a931d0296cc0549a",
            "a721ef95ff994d9296b4256b102b3c8f",
            "36abe4f5ac574c64a15d1cd00642fcf2",
            "546bb1f2b4e344a09c770f2a97fbb87d",
            "13a58a37d8864148932714c1c7223f41",
            "e8383e06fe6a4f95a0973e51fc02ea39",
            "251ed22e40ed4e6390ad2801344c3aeb",
            "f505757caecb4bbc8f03cb37d3ce2716",
            "221fa61197b7462fae1737714ab67732",
            "d584c3a4407f41b7932943590a3b26f5",
            "cafc9d6c45b24bc7a0308dfa1920bd8e",
            "a33f442558d74573b9ee23ae4108671d"
          ]
        },
        "id": "pOt3rhr71riE",
        "outputId": "0629e35f-e625-47b1-b3e4-aada1b13e908"
      },
      "source": [
        "data = np.load(\"MiniImagenet_train_Detected_Images_6001_9000.npz\")\n",
        "train_data = data[\"arr_0\"]\n",
        "data = []\n",
        "completed = 0\n",
        "total_train_images = train_data.shape[0]\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "max_num_samples = 500 # Colab crashes with too many images\n",
        "inceptionv3_train_filename = 'inceptionv3_embeddings_train_6001_9000.npz'\n",
        "\n",
        "inceptionv3_train_embedder = embedding_models.InceptionV3EmbeddingWrapper()\n",
        "\n",
        "run_data_through_model(\n",
        "    train_data, \n",
        "    inceptionv3_train_embedder, \n",
        "    inceptionv3_train_filename,\n",
        "    drive,\n",
        "    folderid[0],\n",
        "    total_train_images,\n",
        "    max_num_samples\n",
        "    )\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "\n",
        "max_num_samples = 1000\n",
        "resnet50_train_filename = 'resnet50_embeddings_train_6001_9000.npz'\n",
        "\n",
        "resnet50_train_embedder = embedding_models.Resnet50EmbeddingWrapper()\n",
        "\n",
        "run_data_through_model(\n",
        "    train_data, \n",
        "    resnet50_train_embedder, \n",
        "    resnet50_train_filename,\n",
        "    drive,\n",
        "    folderid[0],\n",
        "    total_train_images,\n",
        "    max_num_samples\n",
        "    )\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "max_num_samples = 2000\n",
        "moco_resnet50_train_filename = 'moco_resnet50_embeddings_train_6001_9000.npz'\n",
        "\n",
        "moco_resnet50_train_embedder = embedding_models.MoCoResnet50EmbeddingWrapper()\n",
        "\n",
        "run_data_through_model(\n",
        "    train_data, \n",
        "    moco_resnet50_train_embedder, \n",
        "    moco_resnet50_train_filename,\n",
        "    drive,\n",
        "    folderid[0],\n",
        "    total_train_images,\n",
        "    max_num_samples\n",
        "    )\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "max_num_samples = 2000\n",
        "pcl_resnet50_train_filename = 'pcl_resnet50_embeddings_train_6001_9000.npz'\n",
        "\n",
        "pcl_resnet50_train_embedder = embedding_models.PCLResnet50EmbeddingWrapper()\n",
        "\n",
        "run_data_through_model(\n",
        "    train_data, \n",
        "    pcl_resnet50_train_embedder, \n",
        "    pcl_resnet50_train_filename,\n",
        "    drive,\n",
        "    folderid[0],\n",
        "    total_train_images,\n",
        "    max_num_samples\n",
        "    )\n",
        "\n",
        "# auth.authenticate_user()\n",
        "# gauth = GoogleAuth()\n",
        "# gauth.credentials = GoogleCredentials.get_application_default()\n",
        "# drive = GoogleDrive(gauth)\n",
        "\n",
        "# max_num_samples = 100\n",
        "# clip_train_filename = 'clip_embeddings_train.npz'\n",
        "\n",
        "# clip_train_embedder = embedding_models.CLIPEmbeddingWrapper()\n",
        "\n",
        "# run_data_through_model(\n",
        "#     train_data, \n",
        "#     clip_train_embedder, \n",
        "#     clip_train_filename,\n",
        "#     drive,\n",
        "#     folderid[0],\n",
        "#     total_train_images,\n",
        "#     max_num_samples\n",
        "#     )\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "max_num_samples = 1000\n",
        "vgg16_train_filename = 'vgg16_embeddings_train_6001_9000.npz'\n",
        "\n",
        "vgg16_train_embedder = embedding_models.VGG16EmbeddingWrapper()\n",
        "\n",
        "run_data_through_model(\n",
        "    train_data, \n",
        "    vgg16_train_embedder, \n",
        "    vgg16_train_filename,\n",
        "    drive,\n",
        "    folderid[0],\n",
        "    total_train_images,\n",
        "    max_num_samples\n",
        "    )\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "max_num_samples = 2000\n",
        "simclr_train_filename = 'simclr_embeddings_train_6001_9000.npz'\n",
        "\n",
        "simclr_train_embedder = embedding_models.SimCLREmbeddingWrapper()\n",
        "\n",
        "run_data_through_model(\n",
        "    train_data, \n",
        "    simclr_train_embedder, \n",
        "    simclr_train_filename,\n",
        "    drive,\n",
        "    folderid[0],\n",
        "    total_train_images,\n",
        "    max_num_samples\n",
        "    )\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "max_num_samples = 1500\n",
        "swav_resnet50_train_filename = 'swav_resnet50_embeddings_train_6001_9000.npz'\n",
        "\n",
        "swav_resnet50_train_embedder = embedding_models.SwAVResnet50EmbeddingWrapper()\n",
        "\n",
        "run_data_through_model(\n",
        "    train_data, \n",
        "    swav_resnet50_train_embedder, \n",
        "    swav_resnet50_train_filename,\n",
        "    drive,\n",
        "    folderid[0],\n",
        "    total_train_images,\n",
        "    max_num_samples\n",
        "    )"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 0s 0us/step\n",
            "Running for image indices 0-500.\n",
            "Data saved to inceptionv3_embeddings_train_6001_9000.npz\n",
            "Uploaded inceptionv3_embeddings_train_6001_9000.npz to https://drive.google.com/drive/u/1/folders/136KFUQrN06W8qj2IKImshmpeYS2BerQI\n",
            "500/4800 images done\n",
            "Downloading inceptionv3_embeddings_train_6001_9000.npz from GDrive\n",
            "500/4800 images done already\n",
            "Running for image indices 500-1000.\n",
            "Deleting inceptionv3_embeddings_train_6001_9000.npz from GDrive\n",
            "Data saved to inceptionv3_embeddings_train_6001_9000.npz\n",
            "Uploaded inceptionv3_embeddings_train_6001_9000.npz to https://drive.google.com/drive/u/1/folders/136KFUQrN06W8qj2IKImshmpeYS2BerQI\n",
            "1000/4800 images done\n",
            "Downloading inceptionv3_embeddings_train_6001_9000.npz from GDrive\n",
            "1000/4800 images done already\n",
            "Running for image indices 1000-1500.\n",
            "Deleting inceptionv3_embeddings_train_6001_9000.npz from GDrive\n",
            "Data saved to inceptionv3_embeddings_train_6001_9000.npz\n",
            "Uploaded inceptionv3_embeddings_train_6001_9000.npz to https://drive.google.com/drive/u/1/folders/136KFUQrN06W8qj2IKImshmpeYS2BerQI\n",
            "1500/4800 images done\n",
            "Downloading inceptionv3_embeddings_train_6001_9000.npz from GDrive\n",
            "1500/4800 images done already\n",
            "Running for image indices 1500-2000.\n",
            "Deleting inceptionv3_embeddings_train_6001_9000.npz from GDrive\n",
            "Data saved to inceptionv3_embeddings_train_6001_9000.npz\n",
            "Uploaded inceptionv3_embeddings_train_6001_9000.npz to https://drive.google.com/drive/u/1/folders/136KFUQrN06W8qj2IKImshmpeYS2BerQI\n",
            "2000/4800 images done\n",
            "Downloading inceptionv3_embeddings_train_6001_9000.npz from GDrive\n",
            "2000/4800 images done already\n",
            "Running for image indices 2000-2500.\n",
            "Deleting inceptionv3_embeddings_train_6001_9000.npz from GDrive\n",
            "Data saved to inceptionv3_embeddings_train_6001_9000.npz\n",
            "Uploaded inceptionv3_embeddings_train_6001_9000.npz to https://drive.google.com/drive/u/1/folders/136KFUQrN06W8qj2IKImshmpeYS2BerQI\n",
            "2500/4800 images done\n",
            "Downloading inceptionv3_embeddings_train_6001_9000.npz from GDrive\n",
            "2500/4800 images done already\n",
            "Running for image indices 2500-3000.\n",
            "Deleting inceptionv3_embeddings_train_6001_9000.npz from GDrive\n",
            "Data saved to inceptionv3_embeddings_train_6001_9000.npz\n",
            "Uploaded inceptionv3_embeddings_train_6001_9000.npz to https://drive.google.com/drive/u/1/folders/136KFUQrN06W8qj2IKImshmpeYS2BerQI\n",
            "3000/4800 images done\n",
            "Downloading inceptionv3_embeddings_train_6001_9000.npz from GDrive\n",
            "3000/4800 images done already\n",
            "Running for image indices 3000-3500.\n",
            "Deleting inceptionv3_embeddings_train_6001_9000.npz from GDrive\n",
            "Data saved to inceptionv3_embeddings_train_6001_9000.npz\n",
            "Uploaded inceptionv3_embeddings_train_6001_9000.npz to https://drive.google.com/drive/u/1/folders/136KFUQrN06W8qj2IKImshmpeYS2BerQI\n",
            "3500/4800 images done\n",
            "Downloading inceptionv3_embeddings_train_6001_9000.npz from GDrive\n",
            "3500/4800 images done already\n",
            "Running for image indices 3500-4000.\n",
            "Deleting inceptionv3_embeddings_train_6001_9000.npz from GDrive\n",
            "Data saved to inceptionv3_embeddings_train_6001_9000.npz\n",
            "Uploaded inceptionv3_embeddings_train_6001_9000.npz to https://drive.google.com/drive/u/1/folders/136KFUQrN06W8qj2IKImshmpeYS2BerQI\n",
            "4000/4800 images done\n",
            "Downloading inceptionv3_embeddings_train_6001_9000.npz from GDrive\n",
            "4000/4800 images done already\n",
            "Running for image indices 4000-4500.\n",
            "Deleting inceptionv3_embeddings_train_6001_9000.npz from GDrive\n",
            "Data saved to inceptionv3_embeddings_train_6001_9000.npz\n",
            "Uploaded inceptionv3_embeddings_train_6001_9000.npz to https://drive.google.com/drive/u/1/folders/136KFUQrN06W8qj2IKImshmpeYS2BerQI\n",
            "4500/4800 images done\n",
            "Downloading inceptionv3_embeddings_train_6001_9000.npz from GDrive\n",
            "4500/4800 images done already\n",
            "Running for image indices 4500-5000.\n",
            "Deleting inceptionv3_embeddings_train_6001_9000.npz from GDrive\n",
            "Data saved to inceptionv3_embeddings_train_6001_9000.npz\n",
            "Uploaded inceptionv3_embeddings_train_6001_9000.npz to https://drive.google.com/drive/u/1/folders/136KFUQrN06W8qj2IKImshmpeYS2BerQI\n",
            "4800/4800 images done\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e1e211bf9f1a4b769113d28a00437abe",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=102502400.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Running for image indices 0-1000.\n",
            "Data saved to resnet50_embeddings_train_6001_9000.npz\n",
            "Uploaded resnet50_embeddings_train_6001_9000.npz to https://drive.google.com/drive/u/1/folders/136KFUQrN06W8qj2IKImshmpeYS2BerQI\n",
            "1000/4800 images done\n",
            "Downloading resnet50_embeddings_train_6001_9000.npz from GDrive\n",
            "1000/4800 images done already\n",
            "Running for image indices 1000-2000.\n",
            "Deleting resnet50_embeddings_train_6001_9000.npz from GDrive\n",
            "Data saved to resnet50_embeddings_train_6001_9000.npz\n",
            "Uploaded resnet50_embeddings_train_6001_9000.npz to https://drive.google.com/drive/u/1/folders/136KFUQrN06W8qj2IKImshmpeYS2BerQI\n",
            "2000/4800 images done\n",
            "Downloading resnet50_embeddings_train_6001_9000.npz from GDrive\n",
            "2000/4800 images done already\n",
            "Running for image indices 2000-3000.\n",
            "Deleting resnet50_embeddings_train_6001_9000.npz from GDrive\n",
            "Data saved to resnet50_embeddings_train_6001_9000.npz\n",
            "Uploaded resnet50_embeddings_train_6001_9000.npz to https://drive.google.com/drive/u/1/folders/136KFUQrN06W8qj2IKImshmpeYS2BerQI\n",
            "3000/4800 images done\n",
            "Downloading resnet50_embeddings_train_6001_9000.npz from GDrive\n",
            "3000/4800 images done already\n",
            "Running for image indices 3000-4000.\n",
            "Deleting resnet50_embeddings_train_6001_9000.npz from GDrive\n",
            "Data saved to resnet50_embeddings_train_6001_9000.npz\n",
            "Uploaded resnet50_embeddings_train_6001_9000.npz to https://drive.google.com/drive/u/1/folders/136KFUQrN06W8qj2IKImshmpeYS2BerQI\n",
            "4000/4800 images done\n",
            "Downloading resnet50_embeddings_train_6001_9000.npz from GDrive\n",
            "4000/4800 images done already\n",
            "Running for image indices 4000-5000.\n",
            "Deleting resnet50_embeddings_train_6001_9000.npz from GDrive\n",
            "Data saved to resnet50_embeddings_train_6001_9000.npz\n",
            "Uploaded resnet50_embeddings_train_6001_9000.npz to https://drive.google.com/drive/u/1/folders/136KFUQrN06W8qj2IKImshmpeYS2BerQI\n",
            "4800/4800 images done\n",
            "Running for image indices 0-2000.\n",
            "Data saved to moco_resnet50_embeddings_train_6001_9000.npz\n",
            "Uploaded moco_resnet50_embeddings_train_6001_9000.npz to https://drive.google.com/drive/u/1/folders/136KFUQrN06W8qj2IKImshmpeYS2BerQI\n",
            "2000/4800 images done\n",
            "Downloading moco_resnet50_embeddings_train_6001_9000.npz from GDrive\n",
            "2000/4800 images done already\n",
            "Running for image indices 2000-4000.\n",
            "Deleting moco_resnet50_embeddings_train_6001_9000.npz from GDrive\n",
            "Data saved to moco_resnet50_embeddings_train_6001_9000.npz\n",
            "Uploaded moco_resnet50_embeddings_train_6001_9000.npz to https://drive.google.com/drive/u/1/folders/136KFUQrN06W8qj2IKImshmpeYS2BerQI\n",
            "4000/4800 images done\n",
            "Downloading moco_resnet50_embeddings_train_6001_9000.npz from GDrive\n",
            "4000/4800 images done already\n",
            "Running for image indices 4000-6000.\n",
            "Deleting moco_resnet50_embeddings_train_6001_9000.npz from GDrive\n",
            "Data saved to moco_resnet50_embeddings_train_6001_9000.npz\n",
            "Uploaded moco_resnet50_embeddings_train_6001_9000.npz to https://drive.google.com/drive/u/1/folders/136KFUQrN06W8qj2IKImshmpeYS2BerQI\n",
            "4800/4800 images done\n",
            "Running for image indices 0-2000.\n",
            "Data saved to pcl_resnet50_embeddings_train_6001_9000.npz\n",
            "Uploaded pcl_resnet50_embeddings_train_6001_9000.npz to https://drive.google.com/drive/u/1/folders/136KFUQrN06W8qj2IKImshmpeYS2BerQI\n",
            "2000/4800 images done\n",
            "Downloading pcl_resnet50_embeddings_train_6001_9000.npz from GDrive\n",
            "2000/4800 images done already\n",
            "Running for image indices 2000-4000.\n",
            "Deleting pcl_resnet50_embeddings_train_6001_9000.npz from GDrive\n",
            "Data saved to pcl_resnet50_embeddings_train_6001_9000.npz\n",
            "Uploaded pcl_resnet50_embeddings_train_6001_9000.npz to https://drive.google.com/drive/u/1/folders/136KFUQrN06W8qj2IKImshmpeYS2BerQI\n",
            "4000/4800 images done\n",
            "Downloading pcl_resnet50_embeddings_train_6001_9000.npz from GDrive\n",
            "4000/4800 images done already\n",
            "Running for image indices 4000-6000.\n",
            "Deleting pcl_resnet50_embeddings_train_6001_9000.npz from GDrive\n",
            "Data saved to pcl_resnet50_embeddings_train_6001_9000.npz\n",
            "Uploaded pcl_resnet50_embeddings_train_6001_9000.npz to https://drive.google.com/drive/u/1/folders/136KFUQrN06W8qj2IKImshmpeYS2BerQI\n",
            "4800/4800 images done\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467904/553467096 [==============================] - 3s 0us/step\n",
            "Running for image indices 0-1000.\n",
            "Data saved to vgg16_embeddings_train_6001_9000.npz\n",
            "Uploaded vgg16_embeddings_train_6001_9000.npz to https://drive.google.com/drive/u/1/folders/136KFUQrN06W8qj2IKImshmpeYS2BerQI\n",
            "1000/4800 images done\n",
            "Downloading vgg16_embeddings_train_6001_9000.npz from GDrive\n",
            "1000/4800 images done already\n",
            "Running for image indices 1000-2000.\n",
            "Deleting vgg16_embeddings_train_6001_9000.npz from GDrive\n",
            "Data saved to vgg16_embeddings_train_6001_9000.npz\n",
            "Uploaded vgg16_embeddings_train_6001_9000.npz to https://drive.google.com/drive/u/1/folders/136KFUQrN06W8qj2IKImshmpeYS2BerQI\n",
            "2000/4800 images done\n",
            "Downloading vgg16_embeddings_train_6001_9000.npz from GDrive\n",
            "2000/4800 images done already\n",
            "Running for image indices 2000-3000.\n",
            "Deleting vgg16_embeddings_train_6001_9000.npz from GDrive\n",
            "Data saved to vgg16_embeddings_train_6001_9000.npz\n",
            "Uploaded vgg16_embeddings_train_6001_9000.npz to https://drive.google.com/drive/u/1/folders/136KFUQrN06W8qj2IKImshmpeYS2BerQI\n",
            "3000/4800 images done\n",
            "Downloading vgg16_embeddings_train_6001_9000.npz from GDrive\n",
            "3000/4800 images done already\n",
            "Running for image indices 3000-4000.\n",
            "Deleting vgg16_embeddings_train_6001_9000.npz from GDrive\n",
            "Data saved to vgg16_embeddings_train_6001_9000.npz\n",
            "Uploaded vgg16_embeddings_train_6001_9000.npz to https://drive.google.com/drive/u/1/folders/136KFUQrN06W8qj2IKImshmpeYS2BerQI\n",
            "4000/4800 images done\n",
            "Downloading vgg16_embeddings_train_6001_9000.npz from GDrive\n",
            "4000/4800 images done already\n",
            "Running for image indices 4000-5000.\n",
            "Deleting vgg16_embeddings_train_6001_9000.npz from GDrive\n",
            "Data saved to vgg16_embeddings_train_6001_9000.npz\n",
            "Uploaded vgg16_embeddings_train_6001_9000.npz to https://drive.google.com/drive/u/1/folders/136KFUQrN06W8qj2IKImshmpeYS2BerQI\n",
            "4800/4800 images done\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_19_layer_call_and_return_conditional_losses_16240) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_53_layer_call_and_return_conditional_losses_23562) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_47_layer_call_and_return_conditional_losses_22288) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_6_layer_call_and_return_conditional_losses_30442) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_9_layer_call_and_return_conditional_losses_30802) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_45_layer_call_and_return_conditional_losses_35122) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_46_layer_call_and_return_conditional_losses_22072) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_46_layer_call_and_return_conditional_losses_35242) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_30_layer_call_and_return_conditional_losses_33322) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_2_layer_call_and_return_conditional_losses_29962) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_17_layer_call_and_return_conditional_losses_15808) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_35_layer_call_and_return_conditional_losses_33922) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_20_layer_call_and_return_conditional_losses_32122) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_44_layer_call_and_return_conditional_losses_21640) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_42_layer_call_and_return_conditional_losses_34762) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_1_layer_call_and_return_conditional_losses_29842) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_34_layer_call_and_return_conditional_losses_33802) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_55_layer_call_and_return_conditional_losses_23944) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_39_layer_call_and_return_conditional_losses_20560) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_36_layer_call_and_return_conditional_losses_19912) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_21_layer_call_and_return_conditional_losses_32242) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_4_layer_call_and_return_conditional_losses_30202) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_49_layer_call_and_return_conditional_losses_35602) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_38_layer_call_and_return_conditional_losses_34282) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_34_layer_call_and_return_conditional_losses_19480) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_9_layer_call_and_return_conditional_losses_14080) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_52_layer_call_and_return_conditional_losses_35962) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_53_layer_call_and_return_conditional_losses_29512) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_55_layer_call_and_return_conditional_losses_29728) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_49_layer_call_and_return_conditional_losses_22720) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_22_layer_call_and_return_conditional_losses_16888) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_29_layer_call_and_return_conditional_losses_33202) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_43_layer_call_and_return_conditional_losses_34882) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_3_layer_call_and_return_conditional_losses_12784) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_23_layer_call_and_return_conditional_losses_32482) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_44_layer_call_and_return_conditional_losses_35002) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_25_layer_call_and_return_conditional_losses_17536) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_14_layer_call_and_return_conditional_losses_15160) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_42_layer_call_and_return_conditional_losses_21208) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_28_layer_call_and_return_conditional_losses_33082) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_51_layer_call_and_return_conditional_losses_23152) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_layer_call_and_return_conditional_losses_12124) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_40_layer_call_and_return_conditional_losses_20776) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_35_layer_call_and_return_conditional_losses_19696) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_41_layer_call_and_return_conditional_losses_34642) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_18_layer_call_and_return_conditional_losses_16024) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_23_layer_call_and_return_conditional_losses_17104) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_8_layer_call_and_return_conditional_losses_30682) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_3_layer_call_and_return_conditional_losses_30082) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_12_layer_call_and_return_conditional_losses_31162) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_27_layer_call_and_return_conditional_losses_32962) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_6_layer_call_and_return_conditional_losses_13432) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_11_layer_call_and_return_conditional_losses_14512) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_layer_call_and_return_conditional_losses_29403) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_45_layer_call_and_return_conditional_losses_21856) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_39_layer_call_and_return_conditional_losses_34402) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_19_layer_call_and_return_conditional_losses_32002) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_29_layer_call_and_return_conditional_losses_18400) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_4_layer_call_and_return_conditional_losses_13000) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_1_layer_call_and_return_conditional_losses_12352) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_54_layer_call_and_return_conditional_losses_23756) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_41_layer_call_and_return_conditional_losses_20992) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_20_layer_call_and_return_conditional_losses_16456) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_40_layer_call_and_return_conditional_losses_34522) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_32_layer_call_and_return_conditional_losses_33562) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_13_layer_call_and_return_conditional_losses_14944) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_33_layer_call_and_return_conditional_losses_33682) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_30_layer_call_and_return_conditional_losses_18616) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_17_layer_call_and_return_conditional_losses_31762) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_7_layer_call_and_return_conditional_losses_30562) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_48_layer_call_and_return_conditional_losses_35482) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_12_layer_call_and_return_conditional_losses_14728) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_5_layer_call_and_return_conditional_losses_30322) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_13_layer_call_and_return_conditional_losses_31282) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_15_layer_call_and_return_conditional_losses_15376) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_18_layer_call_and_return_conditional_losses_31882) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_21_layer_call_and_return_conditional_losses_16672) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_54_layer_call_and_return_conditional_losses_29621) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_48_layer_call_and_return_conditional_losses_22504) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_31_layer_call_and_return_conditional_losses_18832) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_31_layer_call_and_return_conditional_losses_33442) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_16_layer_call_and_return_conditional_losses_31642) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_10_layer_call_and_return_conditional_losses_14296) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_24_layer_call_and_return_conditional_losses_32602) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_5_layer_call_and_return_conditional_losses_13216) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_16_layer_call_and_return_conditional_losses_15592) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_26_layer_call_and_return_conditional_losses_32842) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_28_layer_call_and_return_conditional_losses_18184) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_22_layer_call_and_return_conditional_losses_32362) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_47_layer_call_and_return_conditional_losses_35362) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_38_layer_call_and_return_conditional_losses_20344) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_25_layer_call_and_return_conditional_losses_32722) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_51_layer_call_and_return_conditional_losses_35842) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_50_layer_call_and_return_conditional_losses_35722) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_2_layer_call_and_return_conditional_losses_12568) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_8_layer_call_and_return_conditional_losses_13864) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_52_layer_call_and_return_conditional_losses_23368) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_27_layer_call_and_return_conditional_losses_17968) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_33_layer_call_and_return_conditional_losses_19264) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_26_layer_call_and_return_conditional_losses_17752) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_7_layer_call_and_return_conditional_losses_13648) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_11_layer_call_and_return_conditional_losses_31042) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_15_layer_call_and_return_conditional_losses_31522) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_10_layer_call_and_return_conditional_losses_30922) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_37_layer_call_and_return_conditional_losses_20128) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_37_layer_call_and_return_conditional_losses_34162) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_43_layer_call_and_return_conditional_losses_21424) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_14_layer_call_and_return_conditional_losses_31402) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_24_layer_call_and_return_conditional_losses_17320) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_36_layer_call_and_return_conditional_losses_34042) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_32_layer_call_and_return_conditional_losses_19048) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_50_layer_call_and_return_conditional_losses_22936) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:googleapiclient.discovery_cache:file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 33, in <module>\n",
            "    from oauth2client.contrib.locked_file import LockedFile\n",
            "ModuleNotFoundError: No module named 'oauth2client.contrib.locked_file'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 37, in <module>\n",
            "    from oauth2client.locked_file import LockedFile\n",
            "ModuleNotFoundError: No module named 'oauth2client.locked_file'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/__init__.py\", line 44, in autodetect\n",
            "    from . import file_cache\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 41, in <module>\n",
            "    \"file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\"\n",
            "ImportError: file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Running for image indices 0-2000.\n",
            "Data saved to simclr_embeddings_train_6001_9000.npz\n",
            "Uploaded simclr_embeddings_train_6001_9000.npz to https://drive.google.com/drive/u/1/folders/136KFUQrN06W8qj2IKImshmpeYS2BerQI\n",
            "2000/4800 images done\n",
            "Downloading simclr_embeddings_train_6001_9000.npz from GDrive\n",
            "2000/4800 images done already\n",
            "Running for image indices 2000-4000.\n",
            "Deleting simclr_embeddings_train_6001_9000.npz from GDrive\n",
            "Data saved to simclr_embeddings_train_6001_9000.npz\n",
            "Uploaded simclr_embeddings_train_6001_9000.npz to https://drive.google.com/drive/u/1/folders/136KFUQrN06W8qj2IKImshmpeYS2BerQI\n",
            "4000/4800 images done\n",
            "Downloading simclr_embeddings_train_6001_9000.npz from GDrive\n",
            "4000/4800 images done already\n",
            "Running for image indices 4000-6000.\n",
            "Deleting simclr_embeddings_train_6001_9000.npz from GDrive\n",
            "Data saved to simclr_embeddings_train_6001_9000.npz\n",
            "Uploaded simclr_embeddings_train_6001_9000.npz to https://drive.google.com/drive/u/1/folders/136KFUQrN06W8qj2IKImshmpeYS2BerQI\n",
            "4800/4800 images done\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/facebookresearch/swav/archive/master.zip\" to /root/.cache/torch/hub/master.zip\n",
            "Downloading: \"https://dl.fbaipublicfiles.com/deepcluster/swav_800ep_pretrain.pth.tar\" to /root/.cache/torch/hub/checkpoints/swav_800ep_pretrain.pth.tar\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "13a58a37d8864148932714c1c7223f41",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=113703565.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:googleapiclient.discovery_cache:file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 33, in <module>\n",
            "    from oauth2client.contrib.locked_file import LockedFile\n",
            "ModuleNotFoundError: No module named 'oauth2client.contrib.locked_file'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 37, in <module>\n",
            "    from oauth2client.locked_file import LockedFile\n",
            "ModuleNotFoundError: No module named 'oauth2client.locked_file'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/__init__.py\", line 44, in autodetect\n",
            "    from . import file_cache\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 41, in <module>\n",
            "    \"file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\"\n",
            "ImportError: file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Running for image indices 0-1500.\n",
            "Data saved to swav_resnet50_embeddings_train_6001_9000.npz\n",
            "Uploaded swav_resnet50_embeddings_train_6001_9000.npz to https://drive.google.com/drive/u/1/folders/136KFUQrN06W8qj2IKImshmpeYS2BerQI\n",
            "1500/4800 images done\n",
            "Downloading swav_resnet50_embeddings_train_6001_9000.npz from GDrive\n",
            "1500/4800 images done already\n",
            "Running for image indices 1500-3000.\n",
            "Deleting swav_resnet50_embeddings_train_6001_9000.npz from GDrive\n",
            "Data saved to swav_resnet50_embeddings_train_6001_9000.npz\n",
            "Uploaded swav_resnet50_embeddings_train_6001_9000.npz to https://drive.google.com/drive/u/1/folders/136KFUQrN06W8qj2IKImshmpeYS2BerQI\n",
            "3000/4800 images done\n",
            "Downloading swav_resnet50_embeddings_train_6001_9000.npz from GDrive\n",
            "3000/4800 images done already\n",
            "Running for image indices 3000-4500.\n",
            "Deleting swav_resnet50_embeddings_train_6001_9000.npz from GDrive\n",
            "Data saved to swav_resnet50_embeddings_train_6001_9000.npz\n",
            "Uploaded swav_resnet50_embeddings_train_6001_9000.npz to https://drive.google.com/drive/u/1/folders/136KFUQrN06W8qj2IKImshmpeYS2BerQI\n",
            "4500/4800 images done\n",
            "Downloading swav_resnet50_embeddings_train_6001_9000.npz from GDrive\n",
            "4500/4800 images done already\n",
            "Running for image indices 4500-6000.\n",
            "Deleting swav_resnet50_embeddings_train_6001_9000.npz from GDrive\n",
            "Data saved to swav_resnet50_embeddings_train_6001_9000.npz\n",
            "Uploaded swav_resnet50_embeddings_train_6001_9000.npz to https://drive.google.com/drive/u/1/folders/136KFUQrN06W8qj2IKImshmpeYS2BerQI\n",
            "4800/4800 images done\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}